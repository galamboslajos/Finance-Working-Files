{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba5ed071-0bda-4a3b-9b6b-b09e10dda3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas pyarrow yfinance fortitudo_tech matplotlib numpy\n",
    "#!pip install alpaca-py seaborn fredapi python-dotenv cvxopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c99041b-ebc5-4d6b-b178-0c6cd0081bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching stocks via Alpaca...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  3 of 3 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching commodities & macro via yfinance...\n",
      "Building dataset...\n",
      "\n",
      "=== Dataset Ready ===\n",
      "Assets:     ['CAT', 'CBRE', 'COST', 'DECK', 'GS', 'ISRG', 'NFLX', 'NRG', 'NVDA', 'OKE', 'SHW', 'GC=F']\n",
      "Dimensions: 2540 days × 12 assets\n",
      "Range:      2016-01-06 → 2026-02-11\n",
      "Years:      10.1\n",
      "State vars: ['SP500_ret', 'VIX']\n",
      "\n",
      "── pnl.head() ──\n",
      "                 CAT      CBRE      COST      DECK        GS      ISRG  \\\n",
      "date                                                                     \n",
      "2016-01-06 -0.015924 -0.043989 -0.009262 -0.028832 -0.024758  0.002280   \n",
      "2016-01-07 -0.035029 -0.057534 -0.023154  0.014199 -0.031183 -0.029887   \n",
      "2016-01-08 -0.010064 -0.011329 -0.017665 -0.055606 -0.004182 -0.000671   \n",
      "2016-01-11 -0.029357 -0.020721  0.016974 -0.003121  0.010867  0.005520   \n",
      "2016-01-12  0.002289  0.007944  0.008571 -0.009149 -0.000074  0.004826   \n",
      "\n",
      "                NFLX       NRG      NVDA       OKE       SHW      GC=F  \n",
      "date                                                                    \n",
      "2016-01-06  0.088789 -0.081733 -0.042256 -0.046698 -0.029393  0.012441  \n",
      "2016-01-07 -0.026691  0.020654 -0.040459 -0.061409 -0.027826  0.014366  \n",
      "2016-01-08 -0.028320  0.007047 -0.021759  0.011599  0.000818 -0.008978  \n",
      "2016-01-11  0.031805 -0.102998  0.001797 -0.019127  0.000817 -0.001185  \n",
      "2016-01-12  0.013817 -0.032761  0.016572 -0.034162  0.018339 -0.009990  \n",
      "\n",
      "── state_vars.head() ──\n",
      "            SP500_ret        VIX\n",
      "date                            \n",
      "2016-01-06  -0.013202  20.590000\n",
      "2016-01-07  -0.023986  24.990000\n",
      "2016-01-08  -0.010898  27.010000\n",
      "2016-01-11   0.000853  24.299999\n",
      "2016-01-12   0.007773  22.469999\n",
      "\n",
      "── pnl.tail() ──\n",
      "                 CAT      CBRE      COST      DECK        GS      ISRG  \\\n",
      "date                                                                     \n",
      "2026-02-05 -0.019721  0.001747  0.011120 -0.009668 -0.025382 -0.004545   \n",
      "2026-02-06  0.068221  0.020784  0.011927  0.037777  0.042158  0.024533   \n",
      "2026-02-09  0.021685  0.007691 -0.003572 -0.008263  0.015884  0.009562   \n",
      "2026-02-10  0.000337 -0.003809 -0.026779  0.008782  0.005675  0.004676   \n",
      "2026-02-11  0.043015 -0.130508  0.007089 -0.001299 -0.004647  0.001957   \n",
      "\n",
      "                NFLX       NRG      NVDA       OKE       SHW      GC=F  \n",
      "date                                                                    \n",
      "2026-02-05  0.008818  0.003120 -0.013350  0.001493 -0.021564 -0.012063  \n",
      "2026-02-06  0.016312  0.059663  0.075773  0.017006  0.002600  0.018304  \n",
      "2026-02-09 -0.008920  0.015532  0.024665  0.015640 -0.003820  0.019936  \n",
      "2026-02-10  0.009042  0.004549 -0.007924  0.003962  0.011169 -0.009369  \n",
      "2026-02-11 -0.032012  0.026495  0.007977  0.017107  0.006342  0.013459  \n",
      "\n",
      "── state_vars.tail() ──\n",
      "            SP500_ret        VIX\n",
      "date                            \n",
      "2026-02-05  -0.012327  21.770000\n",
      "2026-02-06   0.019504  20.370001\n",
      "2026-02-09   0.004680  17.360001\n",
      "2026-02-10  -0.003309  17.790001\n",
      "2026-02-11  -0.000049  17.650000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "FFR Walk-Forward Backtest — Block 1: Data & Setup\n",
    "==================================================\n",
    "Fetches and prepares all data needed for the backtest.\n",
    "Assets via Alpaca, macro via yfinance.\n",
    "\n",
    "Contrary to previous configurations, BTU replaced by OKE (full membership since 2010), and APO by GS.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import date\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"env\")\n",
    "\n",
    "# ── config ──\n",
    "assets = [\n",
    "    'NVDA', 'ISRG', 'GS', 'DECK', 'COST', 'CAT',\n",
    "    'OKE', 'SHW', 'NRG', 'NFLX', 'CBRE'\n",
    "]\n",
    "commodities = ['GC=F']\n",
    "macro_tickers = ['^VIX', '^GSPC']\n",
    "start_date = \"2016-01-01\"\n",
    "today = date.today().isoformat()\n",
    "\n",
    "\n",
    "# ── stock data (alpaca) ──\n",
    "def fetch_stocks(tickers, start, end):\n",
    "    from alpaca.data.historical import StockHistoricalDataClient\n",
    "    from alpaca.data.requests import StockBarsRequest\n",
    "    from alpaca.data.timeframe import TimeFrame, TimeFrameUnit\n",
    "    from alpaca.data.enums import DataFeed, Adjustment\n",
    "\n",
    "    client = StockHistoricalDataClient(\n",
    "        api_key=os.environ['ALPACA_API_KEY'],\n",
    "        secret_key=os.environ['ALPACA_SECRET_KEY']\n",
    "    )\n",
    "    req = StockBarsRequest(\n",
    "        symbol_or_symbols=tickers,\n",
    "        timeframe=TimeFrame(1, TimeFrameUnit.Day),\n",
    "        start=pd.to_datetime(start),\n",
    "        end=pd.to_datetime(end),\n",
    "        adjustment=Adjustment.ALL,\n",
    "        feed=DataFeed.SIP\n",
    "    )\n",
    "    bars = client.get_stock_bars(req).df.reset_index()\n",
    "    bars['date'] = bars['timestamp'].dt.date\n",
    "    return bars.pivot_table(index='date', columns='symbol', values='close')\n",
    "\n",
    "\n",
    "# ── macro data (yfinance) ──\n",
    "def fetch_macro(tickers, start, end):\n",
    "    df = yf.download(tickers, start=start, end=end, auto_adjust=True)\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df = df['Close']\n",
    "    df.index = pd.to_datetime(df.index).date\n",
    "    df.index.name = 'date'\n",
    "    df.interpolate(method='linear', inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# ── merge & clean ──\n",
    "def build_dataset(stocks, comms, macro):\n",
    "    prices = pd.merge(stocks, comms, left_index=True, right_index=True, how='inner')\n",
    "    prices = prices.dropna(axis=0, how='any')\n",
    "\n",
    "    state_vars = pd.DataFrame({\n",
    "        'SP500_ret': np.log(macro['^GSPC'] / macro['^GSPC'].shift(1)),\n",
    "        'VIX': macro['^VIX'],\n",
    "    }).reindex(prices.index).ffill().dropna()\n",
    "\n",
    "    common = prices.index.intersection(state_vars.index)\n",
    "    prices = prices.loc[common]\n",
    "    state_vars = state_vars.loc[common]\n",
    "\n",
    "    prices.index = pd.to_datetime(prices.index)\n",
    "    state_vars.index = pd.to_datetime(state_vars.index)\n",
    "\n",
    "    pnl = np.log(prices / prices.shift(1)).dropna()\n",
    "    state_vars = state_vars.loc[pnl.index]\n",
    "\n",
    "    return prices, pnl, state_vars\n",
    "\n",
    "\n",
    "# ── run ──\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Fetching stocks via Alpaca...\")\n",
    "    stocks = fetch_stocks(assets, start_date, today)\n",
    "\n",
    "    print(\"Fetching commodities & macro via yfinance...\")\n",
    "    all_yf = fetch_macro(commodities + macro_tickers, start_date, today)\n",
    "\n",
    "    print(\"Building dataset...\")\n",
    "    prices, pnl, state_vars = build_dataset(\n",
    "        stocks, all_yf[commodities], all_yf[macro_tickers]\n",
    "    )\n",
    "\n",
    "    print(f\"\\n=== Dataset Ready ===\")\n",
    "    print(f\"Assets:     {list(pnl.columns)}\")\n",
    "    print(f\"Dimensions: {pnl.shape[0]} days × {pnl.shape[1]} assets\")\n",
    "    print(f\"Range:      {pnl.index[0].date()} → {pnl.index[-1].date()}\")\n",
    "    print(f\"Years:      {pnl.shape[0]/252:.1f}\")\n",
    "    print(f\"State vars: {list(state_vars.columns)}\")\n",
    "\n",
    "    print(\"\\n── pnl.head() ──\")\n",
    "    print(pnl.head())\n",
    "    print(\"\\n── state_vars.head() ──\")\n",
    "    print(state_vars.head())\n",
    "    print(\"\\n── pnl.tail() ──\")\n",
    "    print(pnl.tail())\n",
    "    print(\"\\n── state_vars.tail() ──\")\n",
    "    print(state_vars.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96b207ae-3098-4263-a8c6-f3368f4f6c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 2016-01-06 → 2018-01-05\n",
      "  505 days × 12 assets\n",
      "  Running stacked optimizer (B=1000)...\n",
      "\n",
      "Strategic Weights:\n",
      "  CAT      9.37%\n",
      "  CBRE     1.54%\n",
      "  COST    12.25%\n",
      "  DECK     4.94%\n",
      "  GS       4.26%\n",
      "  ISRG    13.92%\n",
      "  NFLX     4.03%\n",
      "  NRG      3.12%\n",
      "  NVDA     9.51%\n",
      "  OKE      4.92%\n",
      "  SHW     10.04%\n",
      "  GC=F    22.10%\n",
      "  Sum:   100.0%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "FFR Walk-Forward Backtest — Block 2: Stacked Optimizer\n",
    "======================================================\n",
    "Produces strategic weights via:\n",
    "1. Mean-CVaR efficient frontier (long-only, max 25%, α=0.90)\n",
    "2. Bootstrap mean-uncertainty resampling via entropy pooling\n",
    "3. L-fold exposure stacking (Vorobets 2025)\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import fortitudo.tech as ft\n",
    "\n",
    "\n",
    "def stacked_optimizer(pnl, B=1000, N=100, P=9, pf_index=4, L=20,\n",
    "                      alpha=0.90, max_weight=0.25, seed=3):\n",
    "    \"\"\"Run the full stacked optimizer on a training window.\n",
    "\n",
    "    Args:\n",
    "        pnl:        DataFrame of log-returns (T × I).\n",
    "        B:          number of bootstrap draws for mean uncertainty.\n",
    "        N:          sample size per bootstrap draw.\n",
    "        P:          number of frontier points.\n",
    "        pf_index:   which frontier point to stack around.\n",
    "        L:          number of folds for exposure stacking.\n",
    "        alpha:      CVaR confidence level.\n",
    "        max_weight: upper bound per asset.\n",
    "        seed:       random seed.\n",
    "\n",
    "    Returns:\n",
    "        weights: array of strategic weights (I,).\n",
    "    \"\"\"\n",
    "    R = pnl.values\n",
    "    S, I = R.shape\n",
    "\n",
    "    # constraints: 0 <= w <= max_weight\n",
    "    G = np.vstack((np.eye(I), -np.eye(I)))\n",
    "    h = np.hstack((max_weight * np.ones(I), np.zeros(I)))\n",
    "\n",
    "    # base frontier\n",
    "    cvar_opt = ft.MeanCVaR(R, G, h, alpha=alpha)\n",
    "\n",
    "    # mean-uncertainty bootstrap\n",
    "    stats = ft.simulation_moments(pnl)\n",
    "    means = stats['Mean'].values\n",
    "    cov = ft.covariance_matrix(pnl).values\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    return_sim = np.random.multivariate_normal(means, cov, (N, B))\n",
    "\n",
    "    p = np.ones((S, 1)) / S\n",
    "    frontier_mean = np.full((I, P, B), np.nan)\n",
    "\n",
    "    for b in range(B):\n",
    "        means_b = np.mean(return_sim[:, b, :], axis=0)\n",
    "        q = ft.entropy_pooling(p, A=R.T, b=means_b[:, np.newaxis])\n",
    "        R_weighted = R * q * S\n",
    "        cvar_opt_b = ft.MeanCVaR(R_weighted, G, h, alpha=alpha)\n",
    "        frontier_mean[:, :, b] = cvar_opt_b.efficient_frontier(P)\n",
    "\n",
    "    # exposure stacking\n",
    "    weights = ft.exposure_stacking(L, frontier_mean[:, pf_index, :])\n",
    "\n",
    "    return weights\n",
    "\n",
    "\n",
    "# ── test ──\n",
    "train_end = pnl.index[0] + pd.DateOffset(months=24)\n",
    "pnl_train = pnl.loc[:train_end]\n",
    "\n",
    "print(f\"Training: {pnl_train.index[0].date()} → {pnl_train.index[-1].date()}\")\n",
    "print(f\"  {len(pnl_train)} days × {pnl_train.shape[1]} assets\")\n",
    "print(f\"  Running stacked optimizer (B=1000)...\")\n",
    "\n",
    "w_strategic = stacked_optimizer(pnl_train)\n",
    "\n",
    "print(f\"\\nStrategic Weights:\")\n",
    "for name, w in zip(pnl.columns, w_strategic):\n",
    "    print(f\"  {name:6s} {w*100:6.2f}%\")\n",
    "print(f\"  Sum:   {w_strategic.sum()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6d21c7b-b020-461e-8a14-669023f00ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Regime Thresholds ===\n",
      "  SP500_ret:  Low ≤ -0.00186  |  Mid ≤ 0.00370  |  High\n",
      "  VIX:        Low ≤ 10.81  |  Mid ≤ 14.63  |  High\n",
      "\n",
      "=== State Distribution (9/9 observed) ===\n",
      "  State 0: Growth=Low, VIX=Low  →  9 obs (1.8%)\n",
      "  State 1: Growth=Mid, VIX=Low  →  88 obs (17.4%)\n",
      "  State 2: Growth=High, VIX=Low  →  30 obs (5.9%)\n",
      "  State 3: Growth=Low, VIX=Mid  →  66 obs (13.1%)\n",
      "  State 4: Growth=Mid, VIX=Mid  →  125 obs (24.8%)\n",
      "  State 5: Growth=High, VIX=Mid  →  61 obs (12.1%)\n",
      "  State 6: Growth=Low, VIX=High  →  52 obs (10.3%)\n",
      "  State 7: Growth=Mid, VIX=High  →  39 obs (7.7%)\n",
      "  State 8: Growth=High, VIX=High  →  35 obs (6.9%)\n",
      "\n",
      "Current state: 2  (Growth=High, VIX=Low)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "FFR Walk-Forward Backtest — Block 3: Regime Classification\n",
    "==========================================================\n",
    "3×3 partitioning on SP500_ret and VIX using 25th/75th percentiles.\n",
    "Thresholds computed on training window only.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def classify_3(series, p25, p75):\n",
    "    return np.where(series <= p25, 0, np.where(series <= p75, 1, 2))\n",
    "\n",
    "\n",
    "def compute_regimes(state_vars, thresholds=None):\n",
    "    if thresholds is None:\n",
    "        thresholds = {\n",
    "            'sp_p25':  np.percentile(state_vars['SP500_ret'], 25),\n",
    "            'sp_p75':  np.percentile(state_vars['SP500_ret'], 75),\n",
    "            'vix_p25': np.percentile(state_vars['VIX'], 25),\n",
    "            'vix_p75': np.percentile(state_vars['VIX'], 75),\n",
    "        }\n",
    "    regimes = pd.DataFrame({\n",
    "        'growth': classify_3(state_vars['SP500_ret'], thresholds['sp_p25'], thresholds['sp_p75']),\n",
    "        'vix':    classify_3(state_vars['VIX'], thresholds['vix_p25'], thresholds['vix_p75']),\n",
    "    }, index=state_vars.index)\n",
    "    regimes['state'] = regimes['growth'] + 3 * regimes['vix']\n",
    "    return regimes, thresholds\n",
    "\n",
    "\n",
    "def print_regime_summary(regimes, thresholds):\n",
    "    labels = ['Low', 'Mid', 'High']\n",
    "    print(f\"=== Regime Thresholds ===\")\n",
    "    print(f\"  SP500_ret:  Low ≤ {thresholds['sp_p25']:.5f}  |  Mid ≤ {thresholds['sp_p75']:.5f}  |  High\")\n",
    "    print(f\"  VIX:        Low ≤ {thresholds['vix_p25']:.2f}  |  Mid ≤ {thresholds['vix_p75']:.2f}  |  High\")\n",
    "    print(f\"\\n=== State Distribution ({regimes['state'].nunique()}/9 observed) ===\")\n",
    "    for s in sorted(regimes['state'].unique()):\n",
    "        g, v = s % 3, s // 3\n",
    "        n = (regimes['state'] == s).sum()\n",
    "        print(f\"  State {s}: Growth={labels[g]}, VIX={labels[v]}  →  {n} obs ({n/len(regimes)*100:.1f}%)\")\n",
    "    current = regimes.iloc[-1]\n",
    "    print(f\"\\nCurrent state: {current['state']}  \"\n",
    "          f\"(Growth={labels[current['growth']]}, VIX={labels[current['vix']]})\")\n",
    "\n",
    "\n",
    "# ── test ──\n",
    "train_end = pnl.index[0] + pd.DateOffset(months=24)\n",
    "sv_train = state_vars.loc[:train_end]\n",
    "regimes_train, thresholds = compute_regimes(sv_train)\n",
    "print_regime_summary(regimes_train, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31e2e0f2-f348-4736-ab90-9cee01d46be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting entropy pooling on 505 scenarios, 9 states...\n",
      "States probability matrix: (505, 9)\n",
      "\n",
      "Per-state effective scenarios (higher = more robust):\n",
      "  State 0 (G=Low, V=Low): 19 / 505 scenarios\n",
      "  State 1 (G=Mid, V=Low): 104 / 505 scenarios\n",
      "  State 2 (G=High, V=Low): 43 / 505 scenarios\n",
      "  State 3 (G=Low, V=Mid): 98 / 505 scenarios\n",
      "  State 4 (G=Mid, V=Mid): 192 / 505 scenarios\n",
      "  State 5 (G=High, V=Mid): 87 / 505 scenarios\n",
      "  State 6 (G=Low, V=High): 90 / 505 scenarios\n",
      "  State 7 (G=Mid, V=High): 88 / 505 scenarios\n",
      "  State 8 (G=High, V=High): 60 / 505 scenarios\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "FFR Walk-Forward Backtest — Block 4: Entropy Pooling\n",
    "====================================================\n",
    "For each observed state, solve for a probability vector over training\n",
    "scenarios that matches the state's mean & variance of state variables,\n",
    "while staying close to an exponential-decay prior.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import fortitudo.tech as ft\n",
    "\n",
    "\n",
    "def fit_entropy_pooling(pnl_train, state_vars_train, regimes_train, n_states=9):\n",
    "    \"\"\"Fit state-conditional probability vectors via entropy pooling.\n",
    "\n",
    "    Args:\n",
    "        pnl_train:        DataFrame of training log-returns (T × I).\n",
    "        state_vars_train: DataFrame with ['SP500_ret', 'VIX'] for training.\n",
    "        regimes_train:    DataFrame with 'state' column from compute_regimes.\n",
    "        n_states:         total number of possible states (9 for 3×3).\n",
    "\n",
    "    Returns:\n",
    "        state_probs: dict {state_id: probability vector of length T}.\n",
    "        p_prior:     the exponential decay prior used.\n",
    "    \"\"\"\n",
    "    T = len(pnl_train)\n",
    "    p_prior = ft.exp_decay_probs(pnl_train, half_life=T / 2)\n",
    "\n",
    "    state_var_cols = ['SP500_ret', 'VIX']\n",
    "    state_vals = state_vars_train[state_var_cols].values\n",
    "\n",
    "    observed_states = regimes_train['state'].unique()\n",
    "\n",
    "    # per-state moments\n",
    "    state_means = np.zeros((n_states, len(state_var_cols)))\n",
    "    state_stds = np.zeros((n_states, len(state_var_cols)))\n",
    "    for s in observed_states:\n",
    "        mask = regimes_train['state'].values == s\n",
    "        state_means[s] = np.mean(state_vals[mask], axis=0)\n",
    "        state_stds[s] = np.std(state_vals[mask], axis=0)\n",
    "\n",
    "    # entropy pooling per state\n",
    "    state_probs = {}\n",
    "    for s in observed_states:\n",
    "        mu_s = state_means[s]\n",
    "        sigma_s = state_stds[s]\n",
    "\n",
    "        A = np.vstack((np.ones((1, T)), state_vals.T))\n",
    "        b = np.vstack(([[1]], mu_s[:, np.newaxis]))\n",
    "\n",
    "        G = state_vals.T ** 2\n",
    "        h = (sigma_s ** 2 + mu_s ** 2)[:, np.newaxis]\n",
    "\n",
    "        try:\n",
    "            q = ft.entropy_pooling(p_prior, A, b, G, h)\n",
    "            state_probs[s] = q.flatten()\n",
    "        except:\n",
    "            state_probs[s] = p_prior.flatten()\n",
    "            print(f\"  State {s}: entropy pooling failed, using prior\")\n",
    "\n",
    "    return state_probs, p_prior.flatten()\n",
    "\n",
    "\n",
    "def build_states_prob_matrix(state_probs, regimes_train, n_states=9):\n",
    "    \"\"\"Build T × n_states matrix of normalised probability vectors.\"\"\"\n",
    "    T = len(regimes_train)\n",
    "    states_prob = np.zeros((T, n_states))\n",
    "    for s, q in state_probs.items():\n",
    "        states_prob[:, s] = q / q.sum()\n",
    "    return states_prob\n",
    "\n",
    "\n",
    "# ── test ──\n",
    "train_end = pnl.index[0] + pd.DateOffset(months=24)\n",
    "pnl_train = pnl.loc[:train_end]\n",
    "sv_train = state_vars.loc[:train_end]\n",
    "regimes_train, thresholds = compute_regimes(sv_train)\n",
    "\n",
    "print(f\"Fitting entropy pooling on {len(pnl_train)} scenarios, {regimes_train['state'].nunique()} states...\")\n",
    "state_probs, p_prior = fit_entropy_pooling(pnl_train, sv_train, regimes_train)\n",
    "states_prob = build_states_prob_matrix(state_probs, regimes_train)\n",
    "\n",
    "print(f\"States probability matrix: {states_prob.shape}\")\n",
    "print(f\"\\nPer-state effective scenarios (higher = more robust):\")\n",
    "for s in sorted(state_probs.keys()):\n",
    "    q = state_probs[s] / state_probs[s].sum()\n",
    "    eff = np.exp(-q @ np.log(np.maximum(q, 1e-300)))\n",
    "    g, v = s % 3, s // 3\n",
    "    labels = ['Low', 'Mid', 'High']\n",
    "    print(f\"  State {s} (G={labels[g]}, V={labels[v]}): {eff:.0f} / {len(pnl_train)} scenarios\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00bf4ce7-459c-4fe0-b030-be3a7c660a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Strategic Arm ===\n",
      "  CVaR 90%:      1.02%\n",
      "  Leverage (raw): 9.84x\n",
      "  Leverage (cap): 1.66x\n",
      "  Max position:   $498,000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "FFR Walk-Forward Backtest — Block 6: CVaR Sizing\n",
    "=================================================\n",
    "Compute CVaR from FFR scenarios, derive leverage and\n",
    "max position size for both strategic and tactical arms.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_cvar(returns, alpha=0.90):\n",
    "    cutoff = int((1 - alpha) * len(returns))\n",
    "    return -np.mean(np.sort(returns)[:cutoff])\n",
    "\n",
    "\n",
    "def size_arm(returns_h, weights, equity, risk_budget, alpha=0.90, max_leverage=1.66):\n",
    "    port_returns = returns_h @ weights\n",
    "    cvar = compute_cvar(port_returns, alpha)\n",
    "    leverage_raw = risk_budget / cvar\n",
    "    gross_weight = np.abs(weights).sum()\n",
    "    leverage = min(leverage_raw, max_leverage / gross_weight)\n",
    "    max_position = equity * leverage\n",
    "    notional = max_position * weights\n",
    "\n",
    "    return {\n",
    "        'cvar': cvar,\n",
    "        'leverage_raw': leverage_raw,\n",
    "        'leverage': leverage,\n",
    "        'gross_weight': gross_weight,\n",
    "        'max_position': max_position,\n",
    "        'notional': notional,\n",
    "    }\n",
    "\n",
    "\n",
    "# ── test ──\n",
    "equity_strategic = 300_000\n",
    "tactical_ratio = 0.5\n",
    "risk_budget = 0.10\n",
    "alpha = 0.90\n",
    "\n",
    "strat = size_arm(returns_h, w_strategic, equity_strategic, risk_budget, alpha)\n",
    "\n",
    "print(f\"=== Strategic Arm ===\")\n",
    "print(f\"  CVaR {alpha:.0%}:      {strat['cvar']*100:.2f}%\")\n",
    "print(f\"  Leverage (raw): {strat['leverage_raw']:.2f}x\")\n",
    "print(f\"  Leverage (cap): {strat['leverage']:.2f}x\")\n",
    "print(f\"  Max position:   ${strat['max_position']:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec3a54da-9744-4037-854c-3ce3b5036b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tactical Weights:\n",
      "  CAT     +24.96%\n",
      "  CBRE     +8.56%\n",
      "  COST     +1.81%\n",
      "  DECK     +0.11%\n",
      "  GS       +9.70%\n",
      "  ISRG    +13.77%\n",
      "  NFLX     +1.85%\n",
      "  NRG      +9.51%\n",
      "  NVDA    +15.47%\n",
      "  OKE      -8.17%\n",
      "  SHW      -2.56%\n",
      "  GC=F    +25.00%\n",
      "  Sum:   +100.0%\n",
      "\n",
      "=== Tactical Arm ===\n",
      "  CVaR 90%:      0.69%\n",
      "  Leverage (raw): 14.57x\n",
      "  Leverage (cap): 1.37x\n",
      "  Gross weight:   1.21\n",
      "  Max position:   $204,980\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "FFR Walk-Forward Backtest — Block 7: Tactical Optimizer\n",
    "=======================================================\n",
    "Mean-CVaR optimization on FFR scenario matrix,\n",
    "conditioned on current regime. Allows long/short.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import fortitudo.tech as ft\n",
    "\n",
    "\n",
    "def tactical_optimize(returns_h, alpha=0.90, max_weight=0.25):\n",
    "    I = returns_h.shape[1]\n",
    "    G = np.vstack([np.eye(I), -np.eye(I)])\n",
    "    h = np.hstack([max_weight * np.ones(I), max_weight * np.ones(I)])\n",
    "    cvar_opt = ft.MeanCVaR(returns_h, G, h, alpha=alpha)\n",
    "    return_target = returns_h.mean(axis=0).mean()\n",
    "    weights = np.array(cvar_opt.efficient_portfolio(return_target)).flatten()\n",
    "    return weights\n",
    "\n",
    "\n",
    "# ── test ──\n",
    "alpha = 0.90\n",
    "max_weight = 0.25\n",
    "\n",
    "w_tactical = tactical_optimize(returns_h, alpha, max_weight)\n",
    "\n",
    "print(f\"\\nTactical Weights:\")\n",
    "for name, w in zip(pnl_train.columns, w_tactical):\n",
    "    print(f\"  {name:6s} {w*100:+7.2f}%\")\n",
    "print(f\"  Sum:   {w_tactical.sum()*100:+.1f}%\")\n",
    "\n",
    "equity_tactical = equity_strategic * tactical_ratio\n",
    "tact = size_arm(returns_h, w_tactical, equity_tactical, risk_budget, alpha)\n",
    "\n",
    "print(f\"\\n=== Tactical Arm ===\")\n",
    "print(f\"  CVaR {alpha:.0%}:      {tact['cvar']*100:.2f}%\")\n",
    "print(f\"  Leverage (raw): {tact['leverage_raw']:.2f}x\")\n",
    "print(f\"  Leverage (cap): {tact['leverage']:.2f}x\")\n",
    "print(f\"  Gross weight:   {tact['gross_weight']:.2f}\")\n",
    "print(f\"  Max position:   ${tact['max_position']:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e890888-303e-48ee-8c90-dcc95d63a443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Combined ===\n",
      "  Gross strategic: $     498,000  (1.66x on $300,000)\n",
      "  Gross tactical:  $     249,000  (1.37x on $150,000)\n",
      "  Total leverage:  2.49x on $300,000\n",
      "  ⚠ Exceeds 1.6x cap — would scale down in live loop\n"
     ]
    }
   ],
   "source": [
    "# ── combined leverage ──\n",
    "gross_strat = np.abs(strat['notional']).sum()\n",
    "gross_tact = np.abs(tact['notional']).sum()\n",
    "total_leverage = (gross_strat + gross_tact) / equity_strategic\n",
    "\n",
    "print(f\"\\n=== Combined ===\")\n",
    "print(f\"  Gross strategic: ${gross_strat:>12,.0f}  ({strat['leverage']:.2f}x on ${equity_strategic:,.0f})\")\n",
    "print(f\"  Gross tactical:  ${gross_tact:>12,.0f}  ({tact['leverage']:.2f}x on ${equity_tactical:,.0f})\")\n",
    "print(f\"  Total leverage:  {total_leverage:.2f}x on ${equity_strategic:,.0f}\")\n",
    "if total_leverage > 1.6:\n",
    "    print(f\"  ⚠ Exceeds 1.6x cap — would scale down in live loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e495ac-e31c-4449-ac90-a5ac5b02122a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
