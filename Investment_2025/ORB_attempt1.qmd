---
title: "ORB_NASDAQ_5min"
author: "Lajos Galambos"
format: md
---

## Introduction

This document outlines the implementation of an Opening Range Breakout (ORB) strategy using 5-minute intraday data for the NASDAQ-100 ETF (QQQ). The strategy is designed to capture price movements based on the opening range of the first two 5-minute candles after market open.

The idea to test such approach comes from [a study by Carlo Zarattini, Andrea Barbon, Andrew Aziz (2024)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4729284).

```{r}
#| echo: false
#| warning: false
#| output: false
#| message: false
# install.packages(c("dplyr", "TTR", "lubridate", "arrow"))
library(dplyr)
library(TTR)
library(lubridate)
library(arrow)
df <- read_parquet("~/Desktop/qqq_5min.parquet")
```

## Data

```{r}
#| echo: false
#| warning: false
#| output: false
str(df)
```

Data has been gethered from the EOD API and saved as a Parquet file. The dataset contains 5-minute OHLCV data for QQQ, including datetime, open, high, low, close, volume, and ticker information.

The timezone is set to "America/New_York" to align with the NASDAQ trading hours.

The time span goes from 2020-10-09 to 2025-05-21.

```{r}
#| echo: false
#| warning: false
#| output: false
#| message: false
#install.packages("arrow")
library(arrow)

df <- read_parquet("~/Desktop/qqq_5min.parquet")
head(df, 10)
tail(df, 10)
```

## Returns on the NASDAQ ETF is taken as a benchmark for the strategy performance evaluation

```{r}
#| warning: false
#| message: false
#| echo: false
plot(df$datetime, df$close, type = "l", main = "QQQ Historical Based on 5-Minute Close Prices", xlab = "Datetime", ylab = "Close Price")
```

## Applying the Strategy

1.  The direction of each trade (long or short) was determined by the initial movement of the opening range.
2.  The stop loss was placed at the low of the day (which was the low of the first 5-minute candle) for a long trade, and at the high of the day (which was the high of the first 5-minute candle) for a short trade.
3.  The distance between the entry price and the stop is labeled as Risk(\$R). Returns are also evaluated based on their multiple of this.
4.  We set the profit to the end of the day **(EoD)**, we liquidated the position at market closure.
5.  We assumed a starting capital of \$100,000, a maximum leverage of **10x**, and a commission of \$0.0005/share traded.

## Position Sizing

Position sizing proved to be a choke point of the strategy, as it is crucial to determine how many shares to buy or sell based on the available capital and risk per trade.

The position size is calculated using the following formula (same as in the paper):

* `A` – current account equity (`current_capital`)  
* `p` – `risk_per_trade_pct` (here 0.01 = 1 %)  
* `L` – `max_leverage` (here 10)  
* `P` – entry price  
* `R` – `risk_per_share`  

**Key properties**

* Fixed-fractional: each position risks exactly **1 % of equity**.  
* Hard leverage ceiling: total exposure never exceeds **10 × equity**.  
* Whole-share only: `floor()` ensures no fractional shares.  
* Adaptive: position size automatically shrinks when the stop is wide and grows when the stop is tight, but never breaches either risk or leverage limits.  


```{r}
#| warning: false
#| message: false
#| output: false
#| echo: false
library(dplyr)
library(lubridate)
library(tibble)

run_orb_backtest <- function(df,
                             initial_capital      = 100000,
                             risk_per_trade_pct   = 0.01,    # 1 % of equity
                             commission_per_share = 0.0005,
                             max_leverage         = 10) {
  
  # ── Pre-process ─────────────────────────────────────────────────────────
  df <- df %>% 
    mutate(date = as.Date(datetime),
           time = format(datetime, "%H:%M:%S")) %>% 
    arrange(datetime)
  
  trading_days    <- unique(df$date)
  current_capital <- initial_capital
  trade_log       <- tibble()
  
  # ── Daily loop ──────────────────────────────────────────────────────────
  for (day in trading_days) {
    
    day_data <- df %>% filter(date == day) %>% arrange(datetime)
    if (nrow(day_data) < 2) next
    
    # Opening-range candle (first 5-min bar)
    or_candle <- day_data[1, ]
    if (anyNA(or_candle[c("open","close","high","low")])) next
    
    # Entry candle (second 5-min bar)
    entry_bar   <- day_data[2, ]
    entry_price <- entry_bar$open
    entry_time  <- entry_bar$datetime
    if (is.na(entry_price)) next
    
    # Direction
    direction <- case_when(
      or_candle$close > or_candle$open ~ "Long",
      or_candle$close < or_candle$open ~ "Short",
      TRUE                              ~ NA_character_
    )
    if (is.na(direction)) next
    
    # Stop-loss & per-share risk
    stop_price     <- if (direction == "Long") or_candle$low else or_candle$high
    risk_per_share <- abs(entry_price - stop_price)
    if (risk_per_share <= 0) next
    
    # ── Position sizing (formula in PNG) ──────────────────────────────────
    shares_by_risk    <- (current_capital * risk_per_trade_pct) / risk_per_share
    shares_by_capital <- (current_capital * max_leverage)       / entry_price
    shares_traded     <- as.integer( floor(min(shares_by_risk, shares_by_capital)) )
    if (shares_traded < 1) next
    
    notional_position <- shares_traded * entry_price
    
    # ── Intraday monitoring: Stop-loss or EoD exit ────────────────────────
    after_entry <- day_data %>% filter(datetime >= entry_time)
    
    exit_price  <- NA_real_
    exit_time   <- NA
    exit_reason <- NA_character_
    
    for (i in seq_len(nrow(after_entry))) {
      bar <- after_entry[i, ]
      
      # Skip bars with missing data to avoid NA in logical tests
      if (anyNA(bar[c("high", "low", "close")])) next
      
      hit_sl <- (direction == "Long"  && bar$low  <= stop_price) ||
                (direction == "Short" && bar$high >= stop_price)
      
      if (hit_sl) {
        exit_price  <- stop_price
        exit_time   <- bar$datetime
        exit_reason <- "SL"
        break
      }
      
      # End-of-day exit on final bar
      if (i == nrow(after_entry)) {
        exit_price  <- bar$close
        exit_time   <- bar$datetime
        exit_reason <- "EoD"
      }
    }
    
    # Safety check
    if (is.na(exit_price)) next
    
    # ── P&L calculation ───────────────────────────────────────────────────
    gross_pnl <- if (direction == "Long") {
      (exit_price - entry_price) * shares_traded
    } else {
      (entry_price - exit_price) * shares_traded
    }
    
    commission_total <- shares_traded * commission_per_share * 2
    net_pnl          <- gross_pnl - commission_total
    
    # ── Logging ───────────────────────────────────────────────────────────
    trade_log <- bind_rows(
      trade_log,
      tibble(
        Date             = day,
        EntryTime        = entry_time,
        ExitTime         = exit_time,
        Direction        = direction,
        EntryPrice       = entry_price,
        ExitPrice        = exit_price,
        StopPrice        = stop_price,
        R                = risk_per_share,
        Shares           = shares_traded,
        NotionalPosition = notional_position,
        MarginUsed       = notional_position / max_leverage,
        GrossPnL         = gross_pnl,
        Commission       = commission_total,
        NetPnL           = net_pnl,
        ExitReason       = exit_reason,
        CapitalBefore    = current_capital,
        CapitalAfter     = current_capital + net_pnl
      )
    )
    
    current_capital <- current_capital + net_pnl
  }
  
  trade_log
}

```

```{r}
#| warning: false
#| message: false
#| otput: false
#| echo: false
results <- run_orb_backtest(df)
# View(results)
```

```{r}
#| warning: false
#| message: false
#| output: false
#| echo: false
summarize_orb_performance <- function(trade_log, df, rf = 0.045) {
  if (nrow(trade_log) == 0) {
    message("No trades to summarize.")
    return(NULL)
  }

  library(dplyr)
  library(ggplot2)
  library(lubridate)
  library(scales)
  library(tidyr)
  library(broom)

  # --- Preprocess trade log ---
  trade_log <- trade_log %>%
    mutate(
      R_multiple = NetPnL / (R * Shares),
      ExitTime = as.POSIXct(ExitTime),
      LeverageUsed = NotionalPosition / CapitalBefore
    )

  first_date <- min(trade_log$ExitTime)
  last_date <- max(trade_log$ExitTime)
  total_days <- as.numeric(difftime(last_date, first_date, units = "days"))
  capital_curve <- trade_log$CapitalAfter
  daily_returns <- diff(capital_curve) / head(capital_curve, -1)

  # --- Performance metrics ---
  total_return <- (last(capital_curve) - first(trade_log$CapitalBefore)) / first(trade_log$CapitalBefore)
  annualized_return <- (1 + total_return)^(252 / total_days) - 1
  annualized_vol <- sd(daily_returns, na.rm = TRUE) * sqrt(252)
  annualized_sharpe <- ifelse(annualized_vol > 0,
                              (mean(daily_returns, na.rm = TRUE) * 252 - rf) / annualized_vol,
                              NA)
  cum_max <- cummax(capital_curve)
  drawdowns <- capital_curve / cum_max - 1
  max_dd <- min(drawdowns, na.rm = TRUE)

  # --- Benchmark processing ---
  strat_curve <- trade_log %>%
    mutate(Date = as.Date(ExitTime)) %>%
    group_by(Date) %>%
    summarize(StrategyCapital = max(CapitalAfter), .groups = "drop")

  bh_curve <- df %>%
    filter(Ticker == "QQQ.US") %>%
    mutate(Date = as.Date(datetime)) %>%
    group_by(Date) %>%
    summarize(QQQ_Close = last(close), .groups = "drop") %>%
    filter(Date >= min(strat_curve$Date), Date <= max(strat_curve$Date)) %>%
    mutate(BnH_Capital = first(strat_curve$StrategyCapital) * (QQQ_Close / first(QQQ_Close)))

  # --- Alpha estimation with regression (CAPM style) ---
  merged_returns <- left_join(strat_curve, bh_curve, by = "Date") %>%
    arrange(Date) %>%
    mutate(
      strat_ret = c(NA, diff(StrategyCapital)) / lag(StrategyCapital),
      qqq_ret = c(NA, diff(BnH_Capital)) / lag(BnH_Capital)
    ) %>%
    drop_na(strat_ret, qqq_ret)

  capm_model <- lm(strat_ret ~ qqq_ret, data = merged_returns)
  alpha <- coef(capm_model)[1] * 252  # annualize daily alpha
  beta <- coef(capm_model)[2]

  # --- Summary statistics ---
  stats <- tibble(
    Metric = c(
      "Total Return (%)", "Annualized Return (%)", "Annualized Volatility (%)", "Annualized Sharpe Ratio",
      "Max Drawdown (%)", "CAPM Alpha (%)", "Beta", "Total Trades", "Winning Trades",
      "Losing Trades", "Breakeven Trades", "Win Rate (%)", "Avg Net PnL", "Profit Factor",
      "Total Commission Paid", "Avg Position Notional", "Avg Leverage Used"
    ),
    Value = sprintf("%.4f", c(
      total_return * 100,
      annualized_return * 100,
      annualized_vol * 100,
      annualized_sharpe,
      max_dd * 100,
      alpha * 100,
      beta,
      nrow(trade_log),
      sum(trade_log$NetPnL > 0),
      sum(trade_log$NetPnL < 0),
      sum(trade_log$NetPnL == 0),
      mean(trade_log$NetPnL > 0) * 100,
      mean(trade_log$NetPnL),
      ifelse(sum(trade_log$NetPnL < 0) == 0, NA,
             sum(trade_log$NetPnL[trade_log$NetPnL > 0]) / abs(sum(trade_log$NetPnL[trade_log$NetPnL < 0]))),
      sum(trade_log$Commission),
      mean(trade_log$NotionalPosition),
      mean(trade_log$LeverageUsed)
    ))
  )

  print(stats)

  # --- Plot: Strategy vs Buy & Hold ---
  ggplot(merged_returns, aes(x = Date)) +
    geom_line(aes(y = StrategyCapital, color = "Strategy")) +
    geom_line(aes(y = BnH_Capital, color = "Buy & Hold QQQ")) +
    scale_color_manual(values = c("Strategy" = "steelblue", "Buy & Hold QQQ" = "darkorange")) +
    scale_y_continuous(labels = label_number(scale_cut = cut_short_scale())) +
    labs(
      title = "Equity Curve: Strategy vs Buy & Hold QQQ",
      x = "Date", y = "Capital ($)",
      color = "Legend"
    ) +
    theme_minimal()
}

```

```{r}
#| warning: false
#| message: false
#| echo: false
log <- run_orb_backtest(df)
summarize_orb_performance(log, df)
```


Although the strategy produced mostly alpha returns, which is a key feature of successful trading strategies, the Sharp-ratio remained lower than the stats of the paper (4.5% risk free was assumed).

```{r}
#| warning: false
#| message: false
#| echo: false
#| fig-cap: "Rolling Sharpe Ratio and Monthly PnL"
#| fig-asp: 0.6
# install.packages(c("patchwork"))
library(dplyr)
library(ggplot2)
library(lubridate)
library(zoo)      # rollapply
library(scales)   # pretty axes

# ─────────────────────────────────────────────────────────────
# 1)  20-day rolling Sharpe ratio of daily strategy returns
# ─────────────────────────────────────────────────────────────
daily_curve <- log %>%                         # <- `log` comes from previous chunk
  mutate(Date = as.Date(ExitTime)) %>%
  group_by(Date) %>%
  summarise(Capital = max(CapitalAfter), .groups = "drop") %>%
  arrange(Date) %>%
  mutate(Return = Capital / lag(Capital) - 1)

window <- 20  # trading-day look-back

rolling_sharpe <- daily_curve %>%
  mutate(
    RollingSharpe = rollapply(
      Return,
      width = window,
      FUN   = function(x) {
        m <- mean(x, na.rm = TRUE)
        s <- sd(  x, na.rm = TRUE)
        if (s == 0 || is.na(s)) NA else (m / s) * sqrt(252)
      },
      fill  = NA,
      align = "right"
    )
  )

p1 <- ggplot(rolling_sharpe, aes(Date, RollingSharpe)) +
  geom_line(color = "purple") +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    title = paste0(window, "-Day Rolling Sharpe Ratio"),
    x = NULL, y = "Sharpe"
  ) +
  theme_minimal()

# ─────────────────────────────────────────────────────────────
# 2)  Average monthly Net PnL
# ─────────────────────────────────────────────────────────────
monthly_pnl <- log %>%
  mutate(Month = floor_date(as.Date(ExitTime), "month")) %>%
  group_by(Month) %>%
  summarise(
    AvgPnL   = mean(NetPnL),
    TotalPnL = sum(NetPnL),
    Trades   = n(),
    .groups  = "drop"
  )

p2 <- ggplot(monthly_pnl, aes(Month, AvgPnL)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 0, color = "grey50") +
  scale_y_continuous(labels = dollar_format()) +
  labs(
    title = "Average Monthly Net PnL",
    x = NULL, y = "Average Net PnL ($)"
  ) +
  theme_minimal()

# ─────────────────────────────────────────────────────────────
# Display the two plots one below the other
# (Patchwork is not strictly required; base grid works too)
# ─────────────────────────────────────────────────────────────
library(patchwork)  # if not installed: install.packages("patchwork")
p1 / p2
```


```{r}
#| warning: false
#| message: false
#| echo: false

library(ggplot2)

# Filter valid trades and compute R-multiples
valid_trades <- log %>% 
  filter(!is.na(NetPnL), !is.na(R), R > 0) %>%
  mutate(
    R_Multiple = NetPnL / (R * Shares),
    ExitTime = as.POSIXct(ExitTime)
  )

# Compute key stats
mean_r <- mean(valid_trades$R_Multiple, na.rm = TRUE)
mean_win <- mean(valid_trades$R_Multiple[valid_trades$R_Multiple > 0], na.rm = TRUE)
mean_loss <- mean(valid_trades$R_Multiple[valid_trades$R_Multiple < 0], na.rm = TRUE)
```

```{r}
#| warning: false
#| message: false
#| echo: false
#| eval: false
################## THIS PLOT IS CURRENTLY NOT USED ##################
################## OUTLIERS ARE NOT HANDLED ##################
# Plot
 ggplot(valid_trades, aes(x = ExitTime, y = R_Multiple)) +
  geom_line(color = "steelblue", linewidth = 0.5) +
  geom_point(color = "steelblue", size = 1) +
  geom_hline(yintercept = mean_r, color = "darkred", linetype = "dashed", linewidth = 1) +
  geom_hline(yintercept = mean_win, color = "black", linetype = "dotted", linewidth = 1) +
  geom_hline(yintercept = mean_loss, color = "red", linetype = "dotted", linewidth = 1) +
  labs(
    title = "R-Multiple of Each Trade Over Time",
    x = "Exit Time",
    y = "R Multiple (NetPnL / Risk)"
  ) +
  annotate("text", 
           x = min(valid_trades$ExitTime, na.rm = TRUE), 
           y = mean_r,
           label = paste0("Mean R: ", round(mean_r, 2)),
           vjust = -1, hjust = 0, color = "darkred", size = 4) +
  annotate("text", 
           x = min(valid_trades$ExitTime, na.rm = TRUE), 
           y = mean_win,
           label = paste0("Mean Win R: ", round(mean_win, 2)),
           vjust = -1, hjust = 0, color = "black", size = 4) +
  annotate("text", 
           x = min(valid_trades$ExitTime, na.rm = TRUE), 
           y = mean_loss,
           label = paste0("Mean Loss R: ", round(mean_loss, 2)),
           vjust = 1.5, hjust = 0, color = "red", size = 4) +
  theme_minimal()
```


```{r}
#| warning: false
#| message: false
#| echo: false
library(ggplot2)
library(dplyr)

winning_trades <- valid_trades %>%
  filter(R_Multiple > 0, is.finite(R_Multiple))

mean_win <- mean(winning_trades$R_Multiple, na.rm = TRUE)
x_clip   <- quantile(winning_trades$R_Multiple, 0.99, na.rm = TRUE)  # 99-th pct

ggplot(winning_trades, aes(x = R_Multiple)) +
  geom_histogram(bins = 1000,
                 fill = "steelblue",
                 color = "white",
                 linewidth = 0.5) +
  geom_vline(xintercept = mean_win,
             color      = "darkred",
             linetype   = "dashed",
             linewidth  = 1) +
  coord_cartesian(xlim = c(0, x_clip)) +   # ← zoom
  labs(
    title = "Winning-Trade R-Multiples (0–99th %ile view)",
    x     = "R Multiple (NetPnL / Risk)",
    y     = "Frequency"
  ) +
  annotate("text",
           x = mean_win,
           y = Inf, vjust = -0.5,
           label = paste0("Mean Win R: ", round(mean_win, 2)),
           color = "darkred", size = 4) +
  theme_minimal()

```

The histogram chart shows the mean and the distribution of **winning** returns (in terms of R) on the trades over time.

It looks like that the distribution has a long right tail, which is a good sign for the strategy. The mean of the winning trades is around 9R, which means that the average winning trade returns 9 times the risk taken.

## Example of a valid trades 

```{r}
#| warning: false
#| message: false
#| echo: false
#| fig-cap: "Example Trades (2 × 2) with Unified Legend"
#| fig-asp: 0.6
library(dplyr)
library(ggplot2)
library(lubridate)
library(patchwork)

# ── helper ────────────────────────────────────────────────────────────────
plot_trade <- function(trd, df_day, title_note = "") {
  
  half_width <- dseconds(150)  # 2.5-min candle half-width
  
  ggplot(df_day) +
    # Candlesticks
    geom_linerange(aes(x = datetime, ymin = low, ymax = high),
                   colour = "grey60") +
    geom_rect(
      aes(xmin = datetime - half_width,
          xmax = datetime + half_width,
          ymin = pmin(open, close),
          ymax = pmax(open, close),
          fill = close >= open),
      colour = "grey30", linewidth = .2
    ) +
    scale_fill_manual(values = c(`TRUE` = "#4CAF50", `FALSE` = "#E53935"),
                      guide = "none") +
    
    # Strategy layers *mapped* to a colour legend
    geom_hline(aes(yintercept = trd$StopPrice, colour = "Stop"),
               linetype = "dashed", linewidth = 1) +
    geom_point(aes(x = trd$EntryTime, y = trd$EntryPrice, colour = "Entry"),
               size = 3) +
    geom_point(aes(x = trd$ExitTime,  y = trd$ExitPrice,  colour = "Exit"),
               size = 3) +
    
    scale_colour_manual(
      name   = NULL,
      values = c(Stop = "red", Entry = "blue", Exit = "gold"),
      breaks = c("Entry", "Exit", "Stop")
    ) +
    guides(
      colour = guide_legend(
        override.aes = list(
          linetype = c("blank", "blank", "dashed"),
          shape    = c(16, 16, NA),
          size     = c(3, 3, 1)
        )
      )
    ) +
    
    labs(
      title = paste0(title_note, " — ", format(as.Date(trd$ExitTime), "%Y-%m-%d")),
      x = NULL, y = "Price"
    ) +
    theme_minimal() +
    theme(
      axis.text.x  = element_text(angle = 45, hjust = 1),
      legend.position = "bottom"   # local; will be collected by patchwork
    )
}

# ── pick four illustrative trades ────────────────────────────────────────
tr_long_win  <- valid_trades %>% filter(Direction == "Long",  NetPnL > 0) %>% slice_max(NetPnL, n = 1)
tr_short_win <- valid_trades %>% filter(Direction == "Short", NetPnL > 0) %>% slice_max(NetPnL, n = 1)
tr_big_loss  <- valid_trades %>%                                slice_min(NetPnL, n = 1)
tr_best_R    <- valid_trades %>% filter(R_Multiple == max(R_Multiple, na.rm = TRUE))

examples <- bind_rows(
  mutate(tr_long_win,  tag = "Long Winner"),
  mutate(tr_short_win, tag = "Short Winner"),
  mutate(tr_big_loss,  tag = "Biggest Loser"),
  mutate(tr_best_R,    tag = paste0("Top R (", round(tr_best_R$R_Multiple, 2), ")"))
)

# ── build plots ───────────────────────────────────────────────────────────
plots <- lapply(split(examples, examples$tag), function(row) {
  trd    <- row[1, ]
  day_df <- df %>% filter(as.Date(datetime) == as.Date(trd$ExitTime))
  plot_trade(trd, day_df, trd$tag)
})

# ── arrange 2 × 2 and collect a single legend at the bottom ──────────────
((plots[[1]] | plots[[2]]) / (plots[[3]] | plots[[4]])) +
  plot_layout(guides = "collect") &
  theme(legend.position = "bottom")

```


## Conclusion

The Opening Range Breakout strategy applied to the NASDAQ-100 ETF (QQQ) using 5-minute intraday data has shown potential for generating alpha returns. However, the overall performance, as measured by the Sharpe ratio and other metrics, indicates that the strategy may require improvements in terms of risk management and position sizing. The strategy's reliance on the opening range and the subsequent price action has yielded some profitable trades, but the volatility and drawdowns suggest that further refinement is needed to enhance its robustness and consistency.

```{r}
#| warning: false
#| message: false
#| echo: false
#| output: false
write.csv(valid_trades, "trade_log_qqq.csv", row.names = TRUE)
```


